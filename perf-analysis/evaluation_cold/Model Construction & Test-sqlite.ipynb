{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T15:36:48.356384Z",
     "start_time": "2022-07-03T15:36:48.234208Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "from statistics import mean\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter \n",
    "from matplotlib import rc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from math import sqrt\n",
    "from modAL.models import ActiveLearner, CommitteeRegressor\n",
    "from modAL.disagreement import max_std_sampling\n",
    "import time\n",
    "from statistics import mean, median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_config():\n",
    "    config_option = []\n",
    "    all_possible_configs = []\n",
    "    cache_size_list = [' -DSQLITE_DEFAULT_CACHE_SIZE=4000', ' -DSQLITE_DEFAULT_CACHE_SIZE=2000']\n",
    "    auto_index_list = [' -DSQLITE_OMIT_AUTOMATIC_INDEX', '']\n",
    "    page_size_list = [' -DSQLITE_DEFAULT_PAGE_SIZE=512', ' -DSQLITE_DEFAULT_PAGE_SIZE=1024', ' -DSQLITE_DEFAULT_PAGE_SIZE=2048']\n",
    "    locking_mode_list = [' -DSQLITE_DEFAULT_LOCKING_MODE=0', ' -DSQLITE_DEFAULT_LOCKING_MODE=1']\n",
    "    omit_feature_list = [' -DSQLITE_OMIT_AUTOMATIC_INDEX', ' -DSQLITE_OMIT_BTREECOUNT',\n",
    "                                         ' -DSQLITE_OMIT_BETWEEN_OPTIMIZATION', ' -DSQLITE_OMIT_LIKE_OPTIMIZATION',\n",
    "                                         ' -DSQLITE_OMIT_LOOKASIDE', ' -DSQLITE_OMIT_QUICKBALANCE', ' -DSQLITE_OMIT_OR_OPTIMIZATION',\n",
    "                                         ' -DSQLITE_OMIT_SHARED_CACHE', ' -DSQLITE_OMIT_XFER_OPT']\n",
    "    store_type_list = [' -DSQLITE_TEMP_STORE=0', ' -DSQLITE_TEMP_STORE=1', ' -DSQLITE_TEMP_STORE=2', ' -DSQLITE_TEMP_STORE=3']\n",
    "    disable_feature_list = [' -DSQLITE_DISABLE_LFS', ' -DSQLITE_DISABLE_DIRSYNC']\n",
    "    autovacuum_list = [' -DSQLITE_DEFAULT_AUTOVACUUM=0', ' -DSQLITE_DEFAULT_AUTOVACUUM=1']\n",
    "    eye_2 = np.eye(2)\n",
    "    eye_3 = np.eye(3)\n",
    "    eye_4 = np.eye(4)\n",
    "    eye_9 = np.eye(9)\n",
    "    for cache_size in cache_size_list:\n",
    "        for auto_index in auto_index_list:\n",
    "            for page_size in page_size_list:\n",
    "                for locking_mode in locking_mode_list:\n",
    "                    for omit_feature in omit_feature_list:\n",
    "                        for store_type in store_type_list:\n",
    "                            for disable_feature in disable_feature_list:\n",
    "                                for autovacuum in autovacuum_list:\n",
    "                                    cmd = cache_size\n",
    "                                    cmd += auto_index\n",
    "                                    cmd += page_size\n",
    "                                    cmd += locking_mode\n",
    "                                    cmd += omit_feature\n",
    "                                    cmd += store_type\n",
    "                                    cmd += disable_feature\n",
    "                                    cmd += autovacuum\n",
    "                                    v0 = eye_2[cache_size_list.index(cache_size)]\n",
    "                                    v1 = eye_2[auto_index_list.index(auto_index)]\n",
    "                                    v2 = eye_3[page_size_list.index(page_size)]\n",
    "                                    v3 = eye_2[locking_mode_list.index(locking_mode)]\n",
    "                                    v4 = eye_9[omit_feature_list.index(omit_feature)]\n",
    "                                    v5 = eye_4[store_type_list.index(store_type)]\n",
    "                                    v6 = eye_2[disable_feature_list.index(disable_feature)]\n",
    "                                    v7 = eye_2[autovacuum_list.index(autovacuum)]\n",
    "                                    all_possible_config = np.concatenate((v0, v1, v2, v3, v4, v5, v6, v7), axis=None)\n",
    "                                    all_possible_configs.append(all_possible_config)\n",
    "                                    config_option.append(cmd)\n",
    "    return config_option, all_possible_configs\n",
    "\n",
    "\n",
    "def transfer_config(all_possible_configs):\n",
    "    config_features = np.asarray(all_possible_configs)\n",
    "    return config_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrzip_config, config_signal = generate_config()\n",
    "all_input_signal = transfer_config(config_signal)\n",
    "all_data = pd.read_csv(\"./sqlite.csv\", index_col=0)\n",
    "results = np.asarray(all_data[all_data['commit_num'] == 1]['time'])\n",
    "all_possible_configs_cur = np.asarray(config_signal)\n",
    "config_features = np.asarray(all_input_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoMSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T18:54:00.680448Z",
     "start_time": "2022-07-03T18:53:30.021270Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R2_list = []\n",
    "time_avg = 0\n",
    "for seed_num in range(0,21):\n",
    "    print(seed_num)\n",
    "    np.random.seed(seed_num)\n",
    "    sampled_config_ids = list(np.random.randint(3456, size=15))\n",
    "    initial_idx = np.array_split(sampled_config_ids, 2)\n",
    "\n",
    "    learner_list = [ActiveLearner(\n",
    "                        estimator=XGBRegressor(),\n",
    "                        X_training=config_features[idx], y_training=results[idx]\n",
    "                )\n",
    "                for idx in initial_idx]\n",
    "\n",
    "    # initializing the Committee\n",
    "    committee = CommitteeRegressor(\n",
    "        learner_list=learner_list,\n",
    "        query_strategy=max_std_sampling\n",
    "    )  \n",
    "    n_queries = 140\n",
    "    res_al = []\n",
    "    start = time.time()\n",
    "    for idx in range(n_queries):\n",
    "        X_train = config_features[sampled_config_ids]\n",
    "        y_train = results[sampled_config_ids]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), sampled_config_ids)]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), sampled_config_ids)]\n",
    "        model=XGBRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        Y_predict = model.predict(X_test)\n",
    "        relative_error = []\n",
    "        for i in range(len(X_test)):\n",
    "            RE=abs(y_test[i]-Y_predict[i])\n",
    "            relative_error.append(RE*RE)\n",
    "        res_al.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "        query_idx, query_instance = committee.query(config_features)\n",
    "        sampled_config_ids += list(query_idx)\n",
    "        committee.teach(config_features[query_idx], results[query_idx])\n",
    "    end = time.time()\n",
    "    time_avg = time_avg + end - start \n",
    "    print('time:'+ str(end - start))\n",
    "    R2_list.append(res_al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(0, len(R2_list)):\n",
    "    subset = [R2_list[i][idx] for idx in [15,40,65,70,115]]\n",
    "    data.append(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t = np.transpose(data)\n",
    "for element in data_t:\n",
    "    print(mean(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R2 = np.matrix(R2_list, dtype=np.float32)\n",
    "print(len(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../Compare/AL-XG.npy', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossover and mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_errors(X_train, y_train, regr):\n",
    "    y_preds = regr.predict(X_train)\n",
    "    square_errors = (y_train - y_preds)**2\n",
    "    normalized_errors = (square_errors - square_errors.min()) / (square_errors.max() - square_errors.min())\n",
    "    return square_errors, normalized_errors\n",
    "\n",
    "def get_all_distances(X_train):\n",
    "    dis_metrics = euclidean_distances(X_train, X_train)\n",
    "    dis_metrics_sum = np.sum(dis_metrics, axis=1)\n",
    "    normalized_dis = (dis_metrics_sum - dis_metrics_sum.min()) / (dis_metrics_sum.max() - dis_metrics_sum.min())\n",
    "    return dis_metrics, normalized_dis\n",
    "\n",
    "def get_ids_by_score(normalized_errors, normalized_dis, dis_metrics, sampled_config_ids, already_crossovered_config_id_list, ratio=0.5):\n",
    "    # print(ratio)\n",
    "    all_possible_configs_pairs = []\n",
    "    all_scores = ratio*normalized_errors + (1-ratio)*normalized_dis\n",
    "    sorted_idx_desc = all_scores.argsort()[:][::-1]\n",
    "    # config_id_1 = sorted_idx_desc[0]\n",
    "    dis_median = np.median(dis_metrics)\n",
    "    # dis_median = 0\n",
    "    for config_id_1 in sorted_idx_desc:\n",
    "        # second_idx_desc = get_second_point_list_by_distance(dis_metrics, config_id_1)\n",
    "        for config_id in sorted_idx_desc:\n",
    "            if dis_metrics[config_id_1][config_id] >= dis_median:\n",
    "                config_id_1_ori, config_id_2_ori = sampled_config_ids[config_id_1], sampled_config_ids[config_id]\n",
    "                if config_id_1_ori not in already_crossovered_config_id_list and config_id_2_ori not in already_crossovered_config_id_list:\n",
    "                # if {config_id_1_ori, config_id_2_ori} not in already_crossovered_config_id_list:\n",
    "                    all_possible_configs_pairs.append([config_id_1_ori, config_id_2_ori])\n",
    "                    return config_id_1_ori, config_id_2_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosssover(config_id_1, config_id_2,  weights, sampled_config_ids, already_crossovered_config_id_list):\n",
    "    global count_failed\n",
    "    # dis_metrics, normalized_dis = get_all_weighted_distance(X_train, feature_weights)\n",
    "    # while True:\n",
    "    # TODO: need to be improved\n",
    "\n",
    "    # config_id_1, config_id_2 = get_ids_by_score_new(normalized_errors, normalized_dis, dis_metrics, sampled_config_ids, already_crossovered_config_id_list, ratio)\n",
    "        # config_id_1, config_id_2 = sampled_config_ids[config_id_1], sampled_config_ids[config_id_2]\n",
    "        # if config_id_1 < len(config_features) and config_id_2 < len(config_features):\n",
    "            # break\n",
    "    count_loop = 0\n",
    "    new_configs = []\n",
    "    # refine the weight based on the intuitives\n",
    "    # weights = feature_weights\n",
    "    algo_count = 26\n",
    "    # algo_weight = np.sum(np.absolute(weights)[:algo_count])\n",
    "    algo_weight = np.max(np.absolute(weights)[:algo_count])\n",
    "    # cut_index_prob_raw = np.insert(np.absolute(weights)[algo_count:], 0, algo_weight)\n",
    "    # re_fined_weights = np.concatenate([np.repeat(algo_weight, np.absolute(weights)[algo_count:]])\n",
    "    cut_index_prob_raw = np.insert(np.absolute(weights)[algo_count:], 0, algo_weight)\n",
    "    cut_index_prob = cut_index_prob_raw/cut_index_prob_raw.sum()\n",
    "    already_cut_ids = []\n",
    "\n",
    "    while True:\n",
    "        count_loop += 1\n",
    "        cut_index = np.random.randint(0, 26)\n",
    "        # cut_index = np.random.choice(5, 1, p=cut_index_prob)[0]\n",
    "        if cut_index == 4:\n",
    "            cut_index -= 1\n",
    "        new_config_1 = np.concatenate([all_possible_configs_cur[config_id_1][:cut_index+1], all_possible_configs_cur[config_id_2][cut_index+1:]])\n",
    "        new_config_1_ids = np.where((all_possible_configs_cur==new_config_1).all(axis=1))[0]\n",
    "        if new_config_1_ids.size > 0 and new_config_1_ids[0] not in sampled_config_ids:\n",
    "            # new_config_1_id = np.where((all_possible_configs_cur==new_config_1).all(axis=1))[0][0]\n",
    "            # if new_config_1_id not in sampled_config_ids:\n",
    "            # new_configs.append(new_config_1)\n",
    "            new_config_2 = np.concatenate([all_possible_configs_cur[config_id_2][:cut_index+1], all_possible_configs_cur[config_id_1][cut_index+1:]])\n",
    "            new_config_2_ids = np.where((all_possible_configs_cur==new_config_2).all(axis=1))[0]\n",
    "            if new_config_2_ids.size > 0 and new_config_2_ids[0] not in sampled_config_ids:\n",
    "                new_configs = [new_config_1, new_config_2]\n",
    "                break\n",
    "        if count_loop == 100:\n",
    "            count_failed +=1\n",
    "            new_config_1, new_config_2 = np.random.randint(len(config_features), size=2)\n",
    "            new_configs = [all_possible_configs_cur[config_id_1], all_possible_configs_cur[config_id_2]]\n",
    "            # already_crossovered_config_id_list.append({config_id_1, config_id_2}) \n",
    "            break\n",
    "    # already_crossovered_config_id_list.append({config_id_1, config_id_2})\n",
    "    already_crossovered_config_id_list += [config_id_1, config_id_2]\n",
    "    return new_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(pre_configs, weights):\n",
    "    # weights = regr.coef_\n",
    "    algo_count = 26\n",
    "    algo_weight = np.max(np.absolute(weights)[:algo_count])\n",
    "    # algo_weight = np.sum(np.absolute(weights)[:algo_count])\n",
    "    # algo_weight = np.mean(np.absolute(weights)[:algo_count])\n",
    "    # np.sum(np.absolute(weights)[:algo_count])\n",
    "    # re_fined_weights = np.concatenate([np.repeat(algo_weight, np.absolute(weights)[algo_count:]])\n",
    "    cut_index_prob_raw = np.insert(np.absolute(weights)[algo_count:], 0, algo_weight)\n",
    "    cut_index_prob = cut_index_prob_raw/cut_index_prob_raw.sum()\n",
    "    new_configs = []\n",
    "    config_len = len(pre_configs[0])\n",
    "    for pre_config in pre_configs:\n",
    "        # mut_index = np.random.randint(0, config_len)\n",
    "        mut_index = np.random.choice(len(cut_index_prob), 1, p=cut_index_prob)[0]\n",
    "        loop = 0\n",
    "        while loop<500:\n",
    "            possible_val = np.random.choice(np.unique(all_possible_configs_cur[:, mut_index]))\n",
    "            new_config = pre_config.copy()\n",
    "            if new_config[mut_index] != possible_val:\n",
    "                new_config[mut_index] = possible_val\n",
    "                new_config_ids = np.where((all_possible_configs_cur[:]==new_config).all(axis=1))[0]\n",
    "                loop = loop + 1\n",
    "                if new_config_ids.size > 0:\n",
    "                    break\n",
    "        new_configs.append(new_config)\n",
    "    return new_configs + pre_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_mutate=[]\n",
    "mre_mutate = []\n",
    "time_avg_mutate = 0\n",
    "for rand_num in range(0,21,1):\n",
    "    r_square_list = []\n",
    "    mre = []\n",
    "    mean_squared_list = []\n",
    "    mean_squared_all_list = []\n",
    "    already_crossovered_config_id_list = []\n",
    "    coefs_list = []\n",
    "    count_failed = 0\n",
    "    \n",
    "    print(\"rand_num: \"+str(rand_num))\n",
    "    \n",
    "    np.random.seed(rand_num)\n",
    "    sampled_config_ids = np.random.randint(len(config_features), size=8)\n",
    "    # X_train, X_test, y_train, y_test=train_test_split(config_features,results, test_size=0.8, random_state=rand_num)\n",
    "    try:\n",
    "        start = time.time()\n",
    "        for i in range(32):\n",
    "    \n",
    "            X_train = config_features[sampled_config_ids]\n",
    "            y_train= results[sampled_config_ids]\n",
    "    \n",
    "            X_test = config_features[~np.isin(np.arange(len(config_features)), sampled_config_ids)]\n",
    "            y_test = results[~np.isin(np.arange(len(config_features)), sampled_config_ids)]\n",
    "    \n",
    "            regr = XGBRegressor(learning_rate=0.1)\n",
    "            regr.fit(X_train, y_train)\n",
    "            y_pred = regr.predict(X_test)\n",
    "            # coefs_lst.append(regr.coef_)\n",
    "            y_pred_all = regr.predict(X_test)\n",
    "            \n",
    "            relative_error = []\n",
    "            for i in range(len(X_test)):\n",
    "                RE = abs(y_test[i]-y_pred[i])\n",
    "                relative_error.append(RE*RE)\n",
    "            # mre.append(mean(relative_error)) \n",
    "            r_square_list.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "            mean_squared_list.append(mean_squared_error(y_test, y_pred))\n",
    "            mean_squared_all_list.append(mean_squared_error(y_test, y_pred_all))\n",
    "            feature_weights = regr.feature_importances_\n",
    "            square_errors, normalized_errors = get_all_errors(X_train, y_train, regr)\n",
    "            dis_metrics, normalized_dis = get_all_distances(X_train)\n",
    "            ratio = 0.9\n",
    "            if np.sum(square_errors) < 0.1:\n",
    "                ratio = 0\n",
    "            config_id_1, config_id_2 = get_ids_by_score(normalized_errors, normalized_dis, dis_metrics, sampled_config_ids, already_crossovered_config_id_list, ratio)\n",
    "    \n",
    "            new_configs = crosssover(config_id_1, config_id_2, feature_weights, sampled_config_ids, already_crossovered_config_id_list)\n",
    "            new_configs = mutation(new_configs, feature_weights)\n",
    "    \n",
    "            for new_config in new_configs:\n",
    "                new_config_ids = np.where((all_possible_configs_cur==new_config).all(axis=1))[0]\n",
    "                if new_config_ids.size > 0:\n",
    "                    new_config_id = new_config_ids[0]\n",
    "                    sampled_config_ids = np.append(sampled_config_ids, new_config_id)\n",
    "        r2_mutate.append(r_square_list)\n",
    "        # mre_mutate.append(mre)\n",
    "        end = time.time()\n",
    "        time_avg_mutate = time_avg_mutate + end - start \n",
    "        print(end - start)\n",
    "    except:\n",
    "        print(\"An exception occurred\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(0, len(r2_mutate)):\n",
    "    subset = [r2_mutate[i][idx] for idx in [4,10,17,23,29]]\n",
    "    data.append(subset)\n",
    "\n",
    "data_t = np.transpose(data)\n",
    "for element in data_t:\n",
    "    print(mean(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R2 = np.matrix(r2_mutate, dtype=np.float32)\n",
    "print(len(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../Compare/Mutate.npy', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T05:51:26.734865Z",
     "start_time": "2021-12-28T05:51:17.999453Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_random = []\n",
    "time_random = 0\n",
    "for rand_num in range(0,101,5): \n",
    "    print(rand_num)\n",
    "    start = time.time()\n",
    "    np.random.seed(rand_num)\n",
    "    sampled_config_ids_rand = list(np.random.randint(len(X_train), size=20))\n",
    "\n",
    "    model=RandomForestRegressor()\n",
    "\n",
    "    n_queries = 140\n",
    "    res_al_rand = []\n",
    "    for idx in range(n_queries):\n",
    "        X_train = config_features[sampled_config_ids_rand]\n",
    "        y_train = results[sampled_config_ids_rand]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), sampled_config_ids_rand)]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), sampled_config_ids_rand)]\n",
    "    \n",
    "        model.fit(X_train, y_train)\n",
    "        Y_predict = model.predict(X_test)\n",
    "        relative_error = []\n",
    "        for i in range(len(X_test)):\n",
    "            RE = abs(y_test[i]-Y_predict[i])\n",
    "            relative_error.append(RE*RE)\n",
    "        # res_al_rand.append(mean(relative_error))\n",
    "        res_al_rand.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "        query_idx = np.random.randint(len(config_features), size=1)\n",
    "        sampled_config_ids_rand += list(query_idx)\n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "    time_random += end-start\n",
    "    r2_random.append(res_al_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(0, len(r2_random)):\n",
    "    subset = [r2_random[i][idx] for idx in [5,30,55,80,105]]\n",
    "    data.append(subset)\n",
    "\n",
    "data_t = np.transpose(data)\n",
    "for element in data_t:\n",
    "    print(mean(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = np.matrix(r2_random, dtype=np.float32)\n",
    "np.save('../Compare/Random.npy', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = np.load('../Compare/FLASH/sqlite_AllNumeric.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_list=[]\n",
    "for l in [21, 46, 71, 96, 121]:\n",
    "    r2 = []\n",
    "    for i in range(0, len(index)):\n",
    "        X_train = config_features[index[i,:l]]\n",
    "        y_train = results[index[i,:l]]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), index[i,:l])]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), index[i,:l])]\n",
    "        model=XGBRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        Y_predict = model.predict(X_test)\n",
    "        relative_error = []\n",
    "        for i in range(len(X_test)):\n",
    "            relative_error.append(abs(y_test[i]-Y_predict[i])/y_test[i])\n",
    "        # r2.append(mean(relative_error))\n",
    "        r2.append(model.score(X_test,y_test))\n",
    "    r2_list.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = np.matrix(r2_list, dtype=np.float32)\n",
    "np.save('../Compare/FLASH_sqlite.npy', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.load('../Compare/SPL_Conqueror/sqlite/divDistBased.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_list=[]\n",
    "for l in [21, 46, 71, 96, 121]:\n",
    "    print(l)\n",
    "    r2 = []\n",
    "    for i in range(0, len(index)):\n",
    "        np.random.seed(i)\n",
    "        sampled_config_ids_rand = np.array(np.random.randint(len(X_train), size=20))\n",
    "        sampled_config_ids_rand = np.concatenate((sampled_config_ids_rand, index[i,:l]))\n",
    "        X_train = config_features[sampled_config_ids_rand]\n",
    "        y_train = results[sampled_config_ids_rand]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), sampled_config_ids_rand)]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), sampled_config_ids_rand)]\n",
    "        model=XGBRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        Y_predict = model.predict(X_test)\n",
    "        relative_error = []\n",
    "        for i in range(len(X_test)):\n",
    "            RE = abs(y_test[i]-Y_predict[i])\n",
    "            relative_error.append(RE*RE)\n",
    "        # r2.append(mean(relative_error))\n",
    "        r2.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "    r2_list.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in r2_list:\n",
    "    print(mean(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = np.matrix(r2_list, dtype=np.float32)\n",
    "np.save('../Compare/SPL_Conqueror/SPL_henard_sqlite.npy', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NsbS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.load('../Compare/NsbS/sqlite/NsbS.npy')\n",
    "r2_list=[]\n",
    "for l in [15,40,65,90,115]:\n",
    "    r2 = []\n",
    "    for i in range(0, len(index)):\n",
    "        np.random.seed(i)\n",
    "        sampled_config_ids_rand = np.array(np.random.randint(len(X_train), size=20))\n",
    "        sampled_config_ids_rand = np.concatenate((sampled_config_ids_rand, index[i,:l]))\n",
    "        X_train = config_features[sampled_config_ids_rand]\n",
    "        y_train = results[sampled_config_ids_rand]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), sampled_config_ids_rand)]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), sampled_config_ids_rand)]\n",
    "        model=XGBRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        Y_predict = model.predict(X_test)\n",
    "        relative_error = []\n",
    "        # print(r2_score(y_test, Y_predict))\n",
    "        for i in range(len(X_test)):\n",
    "            RE = abs(y_test[i]-Y_predict[i])\n",
    "            relative_error.append(RE*RE)\n",
    "        r2.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "        # print(r2)\n",
    "        #r2.append(r2_score(y_test, Y_predict))\n",
    "    r2_list.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in r2_list:\n",
    "    print(mean(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(Y_predict, y_test,'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = np.matrix(r2_list, dtype=np.float32)\n",
    "np.save('../Compare/NsbS/sqlite/result.npy', R2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
