{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T15:36:48.356384Z",
     "start_time": "2022-07-03T15:36:48.234208Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter \n",
    "from matplotlib import rc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from math import sqrt\n",
    "from modAL.models import ActiveLearner, CommitteeRegressor\n",
    "from modAL.disagreement import max_std_sampling\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "def powerset(list_name):\n",
    "    s = list(list_name)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "def generate_config():\n",
    "    config_option = []\n",
    "    all_possible_configs = []\n",
    "    configs = ['--gvn ', '--instcombine ', '--inline ', '--jump-threading ', '--simplifycfg ', '--sccp ', '--ipsccp ', '--licm ',\n",
    "               '--iv-users ']\n",
    "    all_combination = powerset(configs)\n",
    "    for x in all_combination:\n",
    "        if len(x) > 0:\n",
    "            cmd = ''\n",
    "            for item in x:\n",
    "                cmd += item\n",
    "            config_option.append(cmd)\n",
    "    for a1 in range(0, 2):\n",
    "        for a2 in range(0, 2):\n",
    "            for a3 in range(0, 2):\n",
    "                for a4 in range(0, 2):\n",
    "                    for a5 in range(0, 2):\n",
    "                        for a6 in range(0, 2):\n",
    "                            for a7 in range(0, 2):\n",
    "                                for a8 in range(0, 2):\n",
    "                                    for a9 in range(0, 2):\n",
    "                                        all_possible_configs.append([a1, a2, a3, a4, a5, a6, a7, a8, a9])\n",
    "    all_possible_configs.remove([0]*9)\n",
    "    return config_option, all_possible_configs\n",
    "\n",
    "\n",
    "def transfer_config(all_possible_configs):\n",
    "    config_features = np.asarray(all_possible_configs)\n",
    "    return config_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrzip_config, config_signal = generate_config()\n",
    "all_input_signal = transfer_config(config_signal)\n",
    "all_data = pd.read_csv(\"./llvm.csv\", index_col=0)\n",
    "results = np.asarray(all_data[all_data['commit_num'] == 0]['time'])\n",
    "all_possible_configs_cur = np.asarray(config_signal)\n",
    "config_features = np.asarray(all_input_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoMSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T18:54:00.680448Z",
     "start_time": "2022-07-03T18:53:30.021270Z"
    }
   },
   "outputs": [],
   "source": [
    "R2_list = []\n",
    "time_avg = 0\n",
    "for seed_num in range(0,20):\n",
    "    print(seed_num)\n",
    "    np.random.seed(seed_num)\n",
    "    sampled_config_ids = list(np.random.randint(len(results), size=6))\n",
    "    initial_idx = np.array_split(sampled_config_ids, 2)\n",
    "\n",
    "    learner_list = [ActiveLearner(\n",
    "                        estimator=XGBRegressor(),\n",
    "                        X_training=config_features[idx], y_training=results[idx]\n",
    "                )\n",
    "                for idx in initial_idx]\n",
    "\n",
    "    # initializing the Committee\n",
    "    committee = CommitteeRegressor(\n",
    "        learner_list=learner_list,\n",
    "        query_strategy=max_std_sampling\n",
    "    )\n",
    "\n",
    "    model=XGBRegressor()\n",
    "    n_queries = 200\n",
    "    res_al = []\n",
    "    start = time.time()\n",
    "    for idx in range(n_queries):\n",
    "        X_train = config_features[sampled_config_ids]\n",
    "        y_train = results[sampled_config_ids]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), sampled_config_ids)]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), sampled_config_ids)]\n",
    "        model.fit(X_train, y_train)\n",
    "        Y_predict = model.predict(X_test)\n",
    "        relative_error = []\n",
    "        for i in range(len(X_test)):\n",
    "            RE=abs(y_test[i]-Y_predict[i])\n",
    "            relative_error.append(RE*RE)\n",
    "        res_al.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "        # res_al.append(model.score(X_test,y_test))\n",
    "        query_idx, query_instance = committee.query(config_features)\n",
    "        sampled_config_ids += list(query_idx)\n",
    "        committee.teach(config_features[query_idx], results[query_idx])\n",
    "    end = time.time()\n",
    "    time_avg = time_avg + end - start \n",
    "    print('time:'+ str(end - start))\n",
    "    R2_list.append(res_al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(0, len(R2_list)):\n",
    "    subset = [R2_list[i][idx] for idx in range(14, 201, 20)]\n",
    "    data.append(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = np.matrix(R2_list, dtype=np.float32)\n",
    "np.save('../Compare/CoM-XG.npy', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossover and mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_errors(X_train, y_train, regr):\n",
    "    y_preds = regr.predict(X_train)\n",
    "    square_errors = (y_train - y_preds)**2\n",
    "    normalized_errors = (square_errors - square_errors.min()) / (square_errors.max() - square_errors.min())\n",
    "    return square_errors, normalized_errors\n",
    "\n",
    "def get_all_distances(X_train):\n",
    "    dis_metrics = euclidean_distances(X_train, X_train)\n",
    "    dis_metrics_sum = np.sum(dis_metrics, axis=1)\n",
    "    normalized_dis = (dis_metrics_sum - dis_metrics_sum.min()) / (dis_metrics_sum.max() - dis_metrics_sum.min())\n",
    "    return dis_metrics, normalized_dis\n",
    "\n",
    "def get_ids_by_score(normalized_errors, normalized_dis, dis_metrics, sampled_config_ids, already_crossovered_config_id_list, ratio=0.5):\n",
    "    # print(ratio)\n",
    "    all_possible_configs_pairs = []\n",
    "    all_scores = ratio*normalized_errors + (1-ratio)*normalized_dis\n",
    "    sorted_idx_desc = all_scores.argsort()[:][::-1]\n",
    "    # config_id_1 = sorted_idx_desc[0]\n",
    "    dis_median = np.median(dis_metrics)\n",
    "    # dis_median = 0\n",
    "    for config_id_1 in sorted_idx_desc:\n",
    "        # second_idx_desc = get_second_point_list_by_distance(dis_metrics, config_id_1)\n",
    "        for config_id in sorted_idx_desc:\n",
    "            if dis_metrics[config_id_1][config_id] >= dis_median:\n",
    "                config_id_1_ori, config_id_2_ori = sampled_config_ids[config_id_1], sampled_config_ids[config_id]\n",
    "                if config_id_1_ori not in already_crossovered_config_id_list and config_id_2_ori not in already_crossovered_config_id_list:\n",
    "                # if {config_id_1_ori, config_id_2_ori} not in already_crossovered_config_id_list:\n",
    "                    all_possible_configs_pairs.append([config_id_1_ori, config_id_2_ori])\n",
    "                    return config_id_1_ori, config_id_2_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosssover(config_id_1, config_id_2,  weights, sampled_config_ids, already_crossovered_config_id_list):\n",
    "    global count_failed\n",
    "    # dis_metrics, normalized_dis = get_all_weighted_distance(X_train, feature_weights)\n",
    "    # while True:\n",
    "    # TODO: need to be improved\n",
    "\n",
    "    # config_id_1, config_id_2 = get_ids_by_score_new(normalized_errors, normalized_dis, dis_metrics, sampled_config_ids, already_crossovered_config_id_list, ratio)\n",
    "        # config_id_1, config_id_2 = sampled_config_ids[config_id_1], sampled_config_ids[config_id_2]\n",
    "        # if config_id_1 < len(config_features) and config_id_2 < len(config_features):\n",
    "            # break\n",
    "    count_loop = 0\n",
    "    new_configs = []\n",
    "    # refine the weight based on the intuitives\n",
    "    # weights = feature_weights\n",
    "    algo_count = 5\n",
    "    # algo_weight = np.sum(np.absolute(weights)[:algo_count])\n",
    "    algo_weight = np.max(np.absolute(weights)[:algo_count])\n",
    "    # cut_index_prob_raw = np.insert(np.absolute(weights)[algo_count:], 0, algo_weight)\n",
    "    # re_fined_weights = np.concatenate([np.repeat(algo_weight, np.absolute(weights)[algo_count:]])\n",
    "    cut_index_prob_raw = np.insert(np.absolute(weights)[algo_count:], 0, algo_weight)\n",
    "    cut_index_prob = cut_index_prob_raw/cut_index_prob_raw.sum()\n",
    "    already_cut_ids = []\n",
    "\n",
    "    while True:\n",
    "        count_loop += 1\n",
    "        cut_index = np.random.randint(0, 5)\n",
    "        # cut_index = np.random.choice(5, 1, p=cut_index_prob)[0]\n",
    "        if cut_index == 4:\n",
    "            cut_index -= 1\n",
    "        new_config_1 = np.concatenate([all_possible_configs_cur[config_id_1][:cut_index+1], all_possible_configs_cur[config_id_2][cut_index+1:]])\n",
    "        new_config_1_ids = np.where((all_possible_configs_cur==new_config_1).all(axis=1))[0]\n",
    "        if new_config_1_ids.size > 0 and new_config_1_ids[0] not in sampled_config_ids:\n",
    "            # new_config_1_id = np.where((all_possible_configs_cur==new_config_1).all(axis=1))[0][0]\n",
    "            # if new_config_1_id not in sampled_config_ids:\n",
    "            # new_configs.append(new_config_1)\n",
    "            new_config_2 = np.concatenate([all_possible_configs_cur[config_id_2][:cut_index+1], all_possible_configs_cur[config_id_1][cut_index+1:]])\n",
    "            new_config_2_ids = np.where((all_possible_configs_cur==new_config_2).all(axis=1))[0]\n",
    "            if new_config_2_ids.size > 0 and new_config_2_ids[0] not in sampled_config_ids:\n",
    "                new_configs = [new_config_1, new_config_2]\n",
    "                break\n",
    "        if count_loop == 100:\n",
    "            count_failed +=1\n",
    "            new_config_1, new_config_2 = np.random.randint(len(config_features), size=2)\n",
    "            new_configs = [all_possible_configs_cur[config_id_1], all_possible_configs_cur[config_id_2]]\n",
    "            # already_crossovered_config_id_list.append({config_id_1, config_id_2}) \n",
    "            break\n",
    "    # already_crossovered_config_id_list.append({config_id_1, config_id_2})\n",
    "    already_crossovered_config_id_list += [config_id_1, config_id_2]\n",
    "    return new_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(pre_configs, weights):\n",
    "    # weights = regr.coef_\n",
    "    algo_count = 5\n",
    "    algo_weight = np.max(np.absolute(weights)[:algo_count])\n",
    "    # algo_weight = np.sum(np.absolute(weights)[:algo_count])\n",
    "    # algo_weight = np.mean(np.absolute(weights)[:algo_count])\n",
    "    # np.sum(np.absolute(weights)[:algo_count])\n",
    "    # re_fined_weights = np.concatenate([np.repeat(algo_weight, np.absolute(weights)[algo_count:]])\n",
    "    cut_index_prob_raw = np.insert(np.absolute(weights)[algo_count:], 0, algo_weight)\n",
    "    cut_index_prob = cut_index_prob_raw/cut_index_prob_raw.sum()\n",
    "    new_configs = []\n",
    "    config_len = len(pre_configs[0])\n",
    "    for pre_config in pre_configs:\n",
    "        # mut_index = np.random.randint(0, config_len)\n",
    "        mut_index = np.random.choice(5, 1, p=cut_index_prob)[0]\n",
    "        loop = 0\n",
    "        while loop<500:\n",
    "            possible_val = np.random.choice(np.unique(all_possible_configs_cur[:, mut_index]))\n",
    "            new_config = pre_config.copy()\n",
    "            if new_config[mut_index] != possible_val:\n",
    "                new_config[mut_index] = possible_val\n",
    "                new_config_ids = np.where((all_possible_configs_cur[:]==new_config).all(axis=1))[0]\n",
    "                loop = loop + 1\n",
    "                if new_config_ids.size > 0:\n",
    "                    break\n",
    "        new_configs.append(new_config)\n",
    "    return new_configs + pre_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T00:55:14.855480Z",
     "start_time": "2022-01-04T00:55:14.765356Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r2_mutate=[]\n",
    "mre_mutate = []\n",
    "time_avg_mutate = 0\n",
    "for rand_num in range(0,20,1):\n",
    "    r_square_list = []\n",
    "    mre = []\n",
    "    mean_squared_list = []\n",
    "    mean_squared_all_list = []\n",
    "    already_crossovered_config_id_list = []\n",
    "    coefs_list = []\n",
    "    count_failed = 0\n",
    "    \n",
    "    print(\"rand_num: \"+str(rand_num))\n",
    "    \n",
    "    np.random.seed(rand_num)\n",
    "    sampled_config_ids = np.random.randint(len(config_features), size=8)\n",
    "    # X_train, X_test, y_train, y_test=train_test_split(config_features,results, test_size=0.8, random_state=rand_num)\n",
    "    try:\n",
    "        start = time.time()\n",
    "        for i in range(48):\n",
    "    \n",
    "            X_train = config_features[sampled_config_ids]\n",
    "            y_train= results[sampled_config_ids]\n",
    "    \n",
    "            X_test = config_features[~np.isin(np.arange(len(config_features)), sampled_config_ids)]\n",
    "            y_test = results[~np.isin(np.arange(len(config_features)), sampled_config_ids)]\n",
    "    \n",
    "            regr = XGBRegressor(learning_rate=0.1)\n",
    "            regr.fit(X_train, y_train)\n",
    "            y_pred = regr.predict(X_test)\n",
    "            # coefs_lst.append(regr.coef_)\n",
    "            y_pred_all = regr.predict(X_test)\n",
    "            \n",
    "            relative_error = []\n",
    "            for i in range(len(X_test)):\n",
    "                RE=abs(y_test[i]-y_pred[i])\n",
    "                relative_error.append(RE*RE)\n",
    "            mre.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "            # mre.append(mean(relative_error))\n",
    "        \n",
    "            # r_square_list.append(r2_score(y_test, y_pred))\n",
    "            mean_squared_list.append(mean_squared_error(y_test, y_pred))\n",
    "            mean_squared_all_list.append(mean_squared_error(y_test, y_pred_all))\n",
    "            feature_weights = regr.feature_importances_\n",
    "            square_errors, normalized_errors = get_all_errors(X_train, y_train, regr)\n",
    "            dis_metrics, normalized_dis = get_all_distances(X_train)\n",
    "            ratio = 0.9\n",
    "            if np.sum(square_errors) < 0.1:\n",
    "                ratio = 0\n",
    "            config_id_1, config_id_2 = get_ids_by_score(normalized_errors, normalized_dis, dis_metrics, sampled_config_ids, already_crossovered_config_id_list, ratio)\n",
    "    \n",
    "            new_configs = crosssover(config_id_1, config_id_2, feature_weights, sampled_config_ids, already_crossovered_config_id_list)\n",
    "            new_configs = mutation(new_configs, feature_weights)\n",
    "    \n",
    "            for new_config in new_configs:\n",
    "                new_config_ids = np.where((all_possible_configs_cur==new_config).all(axis=1))[0]\n",
    "                if new_config_ids.size > 0:\n",
    "                    new_config_id = new_config_ids[0]\n",
    "                    sampled_config_ids = np.append(sampled_config_ids, new_config_id)\n",
    "        # r2_mutate.append(r_square_list)\n",
    "        mre_mutate.append(mre)\n",
    "        end = time.time()\n",
    "        time_avg_mutate = time_avg_mutate + end - start \n",
    "        print(end - start)\n",
    "    except:\n",
    "        print(\"An exception occurred\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(0, len(R2_list)):\n",
    "    subset = [R2_list[i][idx] for idx in [4,8,12,16,20,24,28,32,36,40]]\n",
    "    data.append(subset)\n",
    "\n",
    "data_t = np.transpose(data)\n",
    "for element in data_t:\n",
    "    print(mean(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "R2 = np.matrix(mre_mutate, dtype=np.float32)\n",
    "print(len(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../Compare/Mutate_mre.npy', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T05:51:26.734865Z",
     "start_time": "2021-12-28T05:51:17.999453Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_random = []\n",
    "time_random = 0\n",
    "for rand_num in range(0,20,1): \n",
    "    print(rand_num)\n",
    "    start = time.time()\n",
    "    np.random.seed(rand_num)\n",
    "    n_queries = 200\n",
    "    res_al_rand = []\n",
    "    for idx in [20, 40, 60, 80, 100, 120, 140, 160, 180, 200]:\n",
    "        sampled_config_ids_rand = list(np.random.randint(len(config_features), size=idx))\n",
    "        X_train = config_features[sampled_config_ids_rand]\n",
    "        y_train = results[sampled_config_ids_rand]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), sampled_config_ids_rand)]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), sampled_config_ids_rand)]\n",
    "        model=RandomForestRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        Y_predict = model.predict(X_test)\n",
    "        relative_error = []\n",
    "        for i in range(len(X_test)):\n",
    "            RE=abs(y_test[i]-Y_predict[i])\n",
    "            relative_error.append(RE*RE)\n",
    "        res_al_rand.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "        # res_al_rand.append(mean(relative_error))\n",
    "        # res_al_rand.append(model.score(X_test,y_test))\n",
    "        # query_idx = np.random.randint(len(config_features), size=1)\n",
    "        # sampled_config_ids_rand += list(query_idx)\n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "    time_random += end-start\n",
    "    r2_random.append(res_al_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t = np.transpose(r2_random)\n",
    "for element in data_t:\n",
    "    print(mean(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = np.matrix(r2_random, dtype=np.float32)\n",
    "np.save('../Compare/Random.npy', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.load('../Compare/FLASH/LLVM_AllNumeric.npy')\n",
    "\n",
    "r2_list=[]\n",
    "for l in [20, 40, 60, 80, 100, 120, 140, 160, 180,200]:\n",
    "    r2 = []\n",
    "    for i in range(0, len(index)):\n",
    "        X_train = config_features[index[i,:l]]\n",
    "        y_train = results[index[i,:l]]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), index[i,:l])]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), index[i,:l])]\n",
    "        model=XGBRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        r2.append(model.score(X_test,y_test))\n",
    "    r2_list.append(r2)\n",
    "\n",
    "R2 = np.matrix(r2_list, dtype=np.float32)\n",
    "np.save('../Compare/FLASH_LLVM.npy', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.load('../Compare/SPL_Conqueror/LLVM/solverBased.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_list=[]\n",
    "for l in [20,40,60,80,100,120,140,160,180,200]:\n",
    "    r2 = []\n",
    "    for i in range(0, len(index)):\n",
    "        X_train = config_features[index[i,:l]]\n",
    "        y_train = results[index[i,:l]]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), index[i,:l])]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), index[i,:l])]\n",
    "        model=XGBRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        relative_error = []\n",
    "        # print(r2_score(y_test, Y_predict))\n",
    "        for i in range(len(X_test)):\n",
    "            RE=abs(y_test[i]-y_pred[i])\n",
    "            relative_error.append(RE*RE)\n",
    "        r2.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "        # r2.append(mean(relative_error))\n",
    "        # r2.append(model.score(X_test,y_test))\n",
    "    r2_list.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in r2_list:\n",
    "    print(mean(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = np.matrix(r2_list, dtype=np.float32)\n",
    "np.save('../Compare/SPL_Conqueror/SPL_divDistBased_LLVM.npy', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NsbS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.load('../Compare/NsbS/llvm/NsbS.npy')\n",
    "print(index)\n",
    "r2_list=[]\n",
    "for l in [20,40,60,80,100,120,140,160,180,200]:\n",
    "    r2 = []\n",
    "    for i in range(0, len(index)):\n",
    "        X_train = config_features[index[i,:l]]\n",
    "        y_train = results[index[i,:l]]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), index[i,:l])]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), index[i,:l])]\n",
    "        model=XGBRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        relative_error = []\n",
    "        # print(r2_score(y_test, Y_predict))\n",
    "        for i in range(len(X_test)):\n",
    "            RE=abs(y_test[i]-y_pred[i])\n",
    "            relative_error.append(RE*RE)\n",
    "        r2.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "        #r2.append(r2_score(y_pred,y_test))\n",
    "    r2_list.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = np.matrix(r2_list, dtype=np.float32)\n",
    "np.save('../Compare/NsbS/llvm/result_mre.npy', R2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
