{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T15:36:48.356384Z",
     "start_time": "2022-07-03T15:36:48.234208Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "from statistics import mean\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter \n",
    "from matplotlib import rc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from math import sqrt\n",
    "from modAL.models import ActiveLearner, CommitteeRegressor\n",
    "from modAL.disagreement import max_std_sampling\n",
    "import time\n",
    "from statistics import mean, median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRZIP Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_config():\n",
    "    config_option = []\n",
    "    all_possible_configs = []\n",
    "    for algorithm in ['-z', '-b', '-g', '-n', '-l']:\n",
    "        for level in range(8, 10):\n",
    "            for window in range(1, 100, 20):\n",
    "                for nice in range(-20, 20, 8):\n",
    "                    for processor in range(1, 5):\n",
    "                        _cmd = 'sudo lrzip {} -L {} -w {} -N {} -p {}'.format(algorithm, level, window, nice, processor)\n",
    "                        all_possible_configs.append([algorithm, level, window, nice, processor])\n",
    "                        config_option.append(_cmd)\n",
    "    return config_option, all_possible_configs\n",
    "\n",
    "\n",
    "def transfer_config(all_possible_configs):\n",
    "    fea_algo_feature = np.eye(5)\n",
    "    fea_algo_list = ['-b', '-g', '-l', '-n', '-z']\n",
    "    all_possible_configs_cur = all_possible_configs\n",
    "    all_possible_configs_cur = np.asanyarray(all_possible_configs_cur)\n",
    "    config_features = []\n",
    "    for possible_config in all_possible_configs_cur:\n",
    "        algo_feature = fea_algo_feature[fea_algo_list.index(possible_config[0])]\n",
    "        config_features.append(np.concatenate([algo_feature, np.asarray(possible_config[1:], dtype=float)]))\n",
    "    config_features = np.asarray(config_features)\n",
    "    scaler = MinMaxScaler()\n",
    "    # scaler = StandardScaler()\n",
    "    scaler.fit(config_features)\n",
    "    config_features = scaler.transform(config_features)\n",
    "    return config_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrzip_config, config_signal = generate_config()\n",
    "all_input_signal = transfer_config(config_signal)\n",
    "all_data = pd.read_csv(\"./lrzip.csv\", index_col=0)\n",
    "results = np.asarray(all_data[all_data['commit_num'] == 1]['time'])\n",
    "all_possible_configs_cur = np.asarray(config_signal)\n",
    "config_features = np.asarray(all_input_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoMSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T18:54:00.680448Z",
     "start_time": "2022-07-03T18:53:30.021270Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R2_list = []\n",
    "RMSE_list = []\n",
    "time_avg = 0\n",
    "for seed_num in range(0,20,1):\n",
    "    print(seed_num)\n",
    "    np.random.seed(seed_num)\n",
    "    sampled_config_ids = list(np.random.randint(1000, size=6))\n",
    "    initial_idx = np.array_split(sampled_config_ids, 2)\n",
    "\n",
    "    learner_list = [ActiveLearner(\n",
    "                        estimator=XGBRegressor(),\n",
    "                        X_training=config_features[idx], y_training=results[idx]\n",
    "                )\n",
    "                for idx in initial_idx]\n",
    "\n",
    "    # initializing the Committee\n",
    "    committee = CommitteeRegressor(\n",
    "        learner_list=learner_list,\n",
    "        query_strategy=max_std_sampling\n",
    "    )\n",
    "\n",
    "    model=XGBRegressor()\n",
    "    n_queries = 54\n",
    "    res_al = []\n",
    "    res_al_r2 = []\n",
    "    start = time.time()\n",
    "    for idx in range(n_queries):\n",
    "        X_train = config_features[sampled_config_ids]\n",
    "        y_train = results[sampled_config_ids]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), sampled_config_ids)]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), sampled_config_ids)]\n",
    "        model.fit(X_train, y_train)\n",
    "        Y_predict = model.predict(X_test)\n",
    "        square_error = []\n",
    "        for i in range(len(X_test)):\n",
    "            RE=abs(y_test[i]-Y_predict[i])\n",
    "            square_error.append(RE*RE)\n",
    "        res_al.append(sqrt(sum(square_error)/len(square_error)))\n",
    "        # print(sum(relative_error)/len(relative_error))\n",
    "        res_al_r2.append(model.score(X_test,y_test))\n",
    "        query_idx, query_instance = committee.query(config_features)\n",
    "        sampled_config_ids += list(query_idx)\n",
    "        committee.teach(config_features[query_idx], results[query_idx])\n",
    "    end = time.time()\n",
    "    time_avg = time_avg + end - start \n",
    "    print('time:'+ str(end - start))\n",
    "    RMSE_list.append(res_al)\n",
    "    R2_list.append(res_al_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('CoM-XG.npy', R2_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossover and mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_errors(X_train, y_train, regr):\n",
    "    y_preds = regr.predict(X_train)\n",
    "    square_errors = (y_train - y_preds)**2\n",
    "    normalized_errors = (square_errors - square_errors.min()) / (square_errors.max() - square_errors.min())\n",
    "    return square_errors, normalized_errors\n",
    "\n",
    "def get_all_distances(X_train):\n",
    "    dis_metrics = euclidean_distances(X_train, X_train)\n",
    "    dis_metrics_sum = np.sum(dis_metrics, axis=1)\n",
    "    normalized_dis = (dis_metrics_sum - dis_metrics_sum.min()) / (dis_metrics_sum.max() - dis_metrics_sum.min())\n",
    "    return dis_metrics, normalized_dis\n",
    "\n",
    "def get_ids_by_score(normalized_errors, normalized_dis, dis_metrics, sampled_config_ids, already_crossovered_config_id_list, ratio=0.5):\n",
    "    # print(ratio)\n",
    "    all_possible_configs_pairs = []\n",
    "    all_scores = ratio*normalized_errors + (1-ratio)*normalized_dis\n",
    "    sorted_idx_desc = all_scores.argsort()[:][::-1]\n",
    "    # config_id_1 = sorted_idx_desc[0]\n",
    "    dis_median = np.median(dis_metrics)\n",
    "    # dis_median = 0\n",
    "    for config_id_1 in sorted_idx_desc:\n",
    "        # second_idx_desc = get_second_point_list_by_distance(dis_metrics, config_id_1)\n",
    "        for config_id in sorted_idx_desc:\n",
    "            if dis_metrics[config_id_1][config_id] >= dis_median:\n",
    "                config_id_1_ori, config_id_2_ori = sampled_config_ids[config_id_1], sampled_config_ids[config_id]\n",
    "                if config_id_1_ori not in already_crossovered_config_id_list and config_id_2_ori not in already_crossovered_config_id_list:\n",
    "                # if {config_id_1_ori, config_id_2_ori} not in already_crossovered_config_id_list:\n",
    "                    all_possible_configs_pairs.append([config_id_1_ori, config_id_2_ori])\n",
    "                    return config_id_1_ori, config_id_2_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosssover(config_id_1, config_id_2,  weights, sampled_config_ids, already_crossovered_config_id_list):\n",
    "    global count_failed\n",
    "    # dis_metrics, normalized_dis = get_all_weighted_distance(X_train, feature_weights)\n",
    "    # while True:\n",
    "    # TODO: need to be improved\n",
    "\n",
    "    # config_id_1, config_id_2 = get_ids_by_score_new(normalized_errors, normalized_dis, dis_metrics, sampled_config_ids, already_crossovered_config_id_list, ratio)\n",
    "        # config_id_1, config_id_2 = sampled_config_ids[config_id_1], sampled_config_ids[config_id_2]\n",
    "        # if config_id_1 < len(config_features) and config_id_2 < len(config_features):\n",
    "            # break\n",
    "    count_loop = 0\n",
    "    new_configs = []\n",
    "    # refine the weight based on the intuitives\n",
    "    # weights = feature_weights\n",
    "    algo_count = 5\n",
    "    # algo_weight = np.sum(np.absolute(weights)[:algo_count])\n",
    "    algo_weight = np.max(np.absolute(weights)[:algo_count])\n",
    "    # cut_index_prob_raw = np.insert(np.absolute(weights)[algo_count:], 0, algo_weight)\n",
    "    # re_fined_weights = np.concatenate([np.repeat(algo_weight, np.absolute(weights)[algo_count:]])\n",
    "    cut_index_prob_raw = np.insert(np.absolute(weights)[algo_count:], 0, algo_weight)\n",
    "    cut_index_prob = cut_index_prob_raw/cut_index_prob_raw.sum()\n",
    "    already_cut_ids = []\n",
    "\n",
    "    while True:\n",
    "        count_loop += 1\n",
    "        cut_index = np.random.randint(0, 5)\n",
    "        # cut_index = np.random.choice(5, 1, p=cut_index_prob)[0]\n",
    "        if cut_index == 4:\n",
    "            cut_index -= 1\n",
    "        new_config_1 = np.concatenate([all_possible_configs_cur[config_id_1][:cut_index+1], all_possible_configs_cur[config_id_2][cut_index+1:]])\n",
    "        new_config_1_ids = np.where((all_possible_configs_cur==new_config_1).all(axis=1))[0]\n",
    "        if new_config_1_ids.size > 0 and new_config_1_ids[0] not in sampled_config_ids:\n",
    "            # new_config_1_id = np.where((all_possible_configs_cur==new_config_1).all(axis=1))[0][0]\n",
    "            # if new_config_1_id not in sampled_config_ids:\n",
    "            # new_configs.append(new_config_1)\n",
    "            new_config_2 = np.concatenate([all_possible_configs_cur[config_id_2][:cut_index+1], all_possible_configs_cur[config_id_1][cut_index+1:]])\n",
    "            new_config_2_ids = np.where((all_possible_configs_cur==new_config_2).all(axis=1))[0]\n",
    "            if new_config_2_ids.size > 0 and new_config_2_ids[0] not in sampled_config_ids:\n",
    "                new_configs = [new_config_1, new_config_2]\n",
    "                break\n",
    "        if count_loop == 100:\n",
    "            count_failed +=1\n",
    "            new_config_1, new_config_2 = np.random.randint(len(config_features), size=2)\n",
    "            new_configs = [all_possible_configs_cur[config_id_1], all_possible_configs_cur[config_id_2]]\n",
    "            # already_crossovered_config_id_list.append({config_id_1, config_id_2}) \n",
    "            break\n",
    "    # already_crossovered_config_id_list.append({config_id_1, config_id_2})\n",
    "    already_crossovered_config_id_list += [config_id_1, config_id_2]\n",
    "    return new_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(pre_configs, weights):\n",
    "    # weights = regr.coef_\n",
    "    algo_count = 5\n",
    "    algo_weight = np.max(np.absolute(weights)[:algo_count])\n",
    "    # algo_weight = np.sum(np.absolute(weights)[:algo_count])\n",
    "    # algo_weight = np.mean(np.absolute(weights)[:algo_count])\n",
    "    # np.sum(np.absolute(weights)[:algo_count])\n",
    "    # re_fined_weights = np.concatenate([np.repeat(algo_weight, np.absolute(weights)[algo_count:]])\n",
    "    cut_index_prob_raw = np.insert(np.absolute(weights)[algo_count:], 0, algo_weight)\n",
    "    cut_index_prob = cut_index_prob_raw/cut_index_prob_raw.sum()\n",
    "    new_configs = []\n",
    "    config_len = len(pre_configs[0])\n",
    "    for pre_config in pre_configs:\n",
    "        # mut_index = np.random.randint(0, config_len)\n",
    "        mut_index = np.random.choice(5, 1, p=cut_index_prob)[0]\n",
    "        while True:\n",
    "            possible_val = np.random.choice(np.unique(all_possible_configs_cur[:, mut_index]))\n",
    "            new_config = pre_config.copy()\n",
    "            if new_config[mut_index] != possible_val:\n",
    "                new_config[mut_index] = possible_val\n",
    "                new_config_ids = np.where((all_possible_configs_cur[:]==new_config).all(axis=1))[0]\n",
    "                if new_config_ids.size > 0:\n",
    "                    break\n",
    "        new_configs.append(new_config)\n",
    "    return new_configs + pre_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T00:55:14.855480Z",
     "start_time": "2022-01-04T00:55:14.765356Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r2_mutate=[]\n",
    "time_avg_mutate = 0\n",
    "for rand_num in range(0,20,1):\n",
    "    r_square_list = []\n",
    "    mean_squared_list = []\n",
    "    mean_squared_all_list = []\n",
    "    already_crossovered_config_id_list = []\n",
    "    coefs_list = []\n",
    "    # sampled_config_ids = np.random.randint(1000, size=6)\n",
    "    count_failed = 0\n",
    "    \n",
    "    print(rand_num)\n",
    "    start = time.time()\n",
    "    np.random.seed(rand_num)\n",
    "    sampled_config_ids = np.random.randint(1000, size=8)\n",
    "    # X_train, X_test, y_train, y_test=train_test_split(config_features,results, test_size=0.8, random_state=rand_num)\n",
    "    try:\n",
    "        for i in range(27):\n",
    "    \n",
    "            X_train = config_features[sampled_config_ids]\n",
    "            y_train= results[sampled_config_ids]\n",
    "    \n",
    "            X_test = config_features[~np.isin(np.arange(len(config_features)), sampled_config_ids)]\n",
    "            y_test = results[~np.isin(np.arange(len(config_features)), sampled_config_ids)]\n",
    "    \n",
    "            regr = XGBRegressor()\n",
    "            regr.fit(X_train, y_train)\n",
    "            y_pred = regr.predict(X_test)\n",
    "            # coefs_lst.append(regr.coef_)\n",
    "            y_pred_all = regr.predict(X_test)\n",
    "            relative_error = []\n",
    "            for i in range(len(X_test)):\n",
    "                RE=abs(y_test[i]-y_pred_all[i])\n",
    "                relative_error.append(RE*RE)\n",
    "                r2.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "            r_square_list.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "        \n",
    "            # r_square_list.append(r2_score(y_test, y_pred))\n",
    "            mean_squared_list.append(mean_squared_error(y_test, y_pred))\n",
    "            mean_squared_all_list.append(mean_squared_error(y_test, y_pred_all))\n",
    "            feature_weights = regr.feature_importances_\n",
    "            square_errors, normalized_errors = get_all_errors(X_train, y_train, regr)\n",
    "            dis_metrics, normalized_dis = get_all_distances(X_train)\n",
    "            ratio = 0.9\n",
    "            if np.sum(square_errors) < 0.1:\n",
    "                ratio = 0\n",
    "            config_id_1, config_id_2 = get_ids_by_score(normalized_errors, normalized_dis, dis_metrics, sampled_config_ids, already_crossovered_config_id_list, ratio)\n",
    "    \n",
    "            new_configs = crosssover(config_id_1, config_id_2, feature_weights, sampled_config_ids, already_crossovered_config_id_list)\n",
    "            new_configs = mutation(new_configs, feature_weights)\n",
    "    \n",
    "            for new_config in new_configs:\n",
    "                new_config_ids = np.where((all_possible_configs_cur==new_config).all(axis=1))[0]\n",
    "                if new_config_ids.size > 0:\n",
    "                    new_config_id = new_config_ids[0]\n",
    "                    sampled_config_ids = np.append(sampled_config_ids, new_config_id)\n",
    "        r2_mutate.append(r_square_list)\n",
    "        end = time.time()\n",
    "        time_avg_mutate = time_avg_mutate + end - start \n",
    "        print(end - start)\n",
    "    except:\n",
    "        print(\"An exception occurred\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R2 = np.matrix(r2_mutate, dtype=np.float32)\n",
    "print(R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./Mutate.npy', R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(0, len(r2_mutate)):\n",
    "    subset = [r2_mutate[i][idx] for idx in [0,7,10,14,17,20]]\n",
    "    data.append(subset)\n",
    "\n",
    "data_t = np.transpose(data)\n",
    "for element in data_t:\n",
    "    print(mean(element))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T05:51:26.734865Z",
     "start_time": "2021-12-28T05:51:17.999453Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_random = []\n",
    "time_random = 0\n",
    "for rand_num in range(0,20,1): \n",
    "    print(rand_num)\n",
    "    start = time.time()\n",
    "    np.random.seed(rand_num)\n",
    "    n_queries = 54\n",
    "    res_al_rand = []\n",
    "    for idx in [9, 18, 27, 36, 45, 54]:\n",
    "        sampled_config_ids_rand = list(np.random.randint(len(config_features), size=idx))\n",
    "        X_train = config_features[sampled_config_ids_rand]\n",
    "        y_train = results[sampled_config_ids_rand]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), sampled_config_ids_rand)]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), sampled_config_ids_rand)]\n",
    "        model=RandomForestRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        Y_predict = model.predict(X_test)\n",
    "        relative_error = []\n",
    "        for i in range(len(X_test)):\n",
    "            RE=abs(y_test[i]-Y_predict[i])\n",
    "            relative_error.append(RE*RE)\n",
    "        res_al_rand.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "    time_random += end-start\n",
    "    r2_random.append(res_al_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time_random/21)\n",
    "R2 = np.matrix(r2_random, dtype=np.float32)\n",
    "print(len(R2))\n",
    "np.save('./Random.npy', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = np.load('../Compare/FLASH/LRZIP_AllNumeric.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_list=[]\n",
    "for l in [9,18,27,36,45,54]:\n",
    "    r2 = []\n",
    "    for i in range(0, len(index)):\n",
    "        X_train = config_features[index[i,:l]]\n",
    "        y_train = results[index[i,:l]]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), index[i,:l])]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), index[i,:l])]\n",
    "        model=XGBRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        Y_predict = model.predict(X_test)\n",
    "        relative_error = []\n",
    "        for i in range(len(X_test)):\n",
    "            relative_error.append(abs(y_test[i]-Y_predict[i])/y_test[i])\n",
    "        r2.append(mean(relative_error))\n",
    "        # r2.append(model.score(X_test,y_test))\n",
    "    r2_list.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = np.matrix(r2_list, dtype=np.float32)\n",
    "    np.save('../Compare/FLASH_LRZIP.npy', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.load('../Compare/SPL_Conqueror/lrzip/divDistBased.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_list=[]\n",
    "for l in range(4, 50, 9):\n",
    "    r2 = []\n",
    "    for i in range(0, len(index)):\n",
    "        np.random.seed(i)\n",
    "        sampled_config_ids_rand = np.array(np.random.randint(len(X_train), size=4))\n",
    "        sampled_config_ids_rand = np.concatenate((sampled_config_ids_rand, index[i,:l]))\n",
    "        X_train = config_features[sampled_config_ids_rand]\n",
    "        y_train = results[sampled_config_ids_rand]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), sampled_config_ids_rand)]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), sampled_config_ids_rand)]\n",
    "        model=XGBRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        Y_predict = model.predict(X_test)\n",
    "        relative_error = []\n",
    "        for i in range(len(X_test)):\n",
    "            RE=abs(y_test[i]-Y_predict[i])\n",
    "            relative_error.append(RE*RE)\n",
    "        r2.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "        # r2.append(model.score(X_test,y_test))\n",
    "    r2_list.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in r2_list:\n",
    "    print(mean(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = np.matrix(r2_list, dtype=np.float32)\n",
    "np.save('../Compare/SPL_Conqueror/SPL_divDistBased_LRZIP_mre.npy', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NsbS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.load('../Compare/NsbS/lrzip/NsbS.npy')\n",
    "r2_list=[]\n",
    "for l in range(4, 50, 9):\n",
    "    r2 = []\n",
    "    for i in range(0, len(index)):\n",
    "        np.random.seed(i)\n",
    "        sampled_config_ids_rand = np.array(np.random.randint(len(X_train), size=4))\n",
    "        sampled_config_ids_rand = np.concatenate((sampled_config_ids_rand, index[i,:l]))\n",
    "        X_train = config_features[sampled_config_ids_rand]\n",
    "        y_train = results[sampled_config_ids_rand]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), sampled_config_ids_rand)]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), sampled_config_ids_rand)]\n",
    "        model=XGBRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        Y_predict = model.predict(X_test)\n",
    "        relative_error = []\n",
    "        # print(r2_score(y_test, Y_predict))\n",
    "        for i in range(len(X_test)):\n",
    "            RE=abs(y_test[i]-Y_predict[i])\n",
    "            relative_error.append(RE*RE)\n",
    "        r2.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "        # print(r2)\n",
    "        #r2.append(model.score(X_test,y_test))\n",
    "    r2_list.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in r2_list:\n",
    "    print(mean(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = np.matrix(r2_list, dtype=np.float32)\n",
    "np.save('../Compare/NsbS/lrzip/result_mre.npy', R2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
