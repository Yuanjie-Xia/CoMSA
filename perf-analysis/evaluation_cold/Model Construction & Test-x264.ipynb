{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T15:36:48.356384Z",
     "start_time": "2022-07-03T15:36:48.234208Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "from statistics import mean, median\n",
    "from math import sqrt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter \n",
    "from matplotlib import rc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from modAL.models import ActiveLearner, CommitteeRegressor\n",
    "from modAL.disagreement import max_std_sampling\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_config():\n",
    "    asm = ['', '--no-asm ']\n",
    "    x8dct = ['', '--no-8x8dct ']\n",
    "    cabac = ['', '--no-cabac ']\n",
    "    deblock = ['', '--no-deblock ']\n",
    "    pskip = ['', '--no-fast-pskip ']\n",
    "    mbtree = ['', '--no-mbtree ']\n",
    "    mixed_refs = ['', '--no-mixed-refs ']\n",
    "    weightb = ['', '--no-weightb ']\n",
    "    rc_lookahead = ['--rc-lookahead 20 ', '--rc-lookahead 40 ']\n",
    "    rc_value = [20, 40]\n",
    "    ref = ['--ref 1 ', '--ref 5 ', '--ref 9 ']\n",
    "    ref_value = [1, 5, 9]\n",
    "    eye_2 = np.eye(2)\n",
    "    config_option = []\n",
    "    all_possible_configs = []\n",
    "    for element0 in asm:\n",
    "        for element1 in x8dct:\n",
    "            for element2 in cabac:\n",
    "                for element3 in deblock:\n",
    "                    for element4 in pskip:\n",
    "                        for element5 in mbtree:\n",
    "                            for element6 in mixed_refs:\n",
    "                                for element7 in weightb:\n",
    "                                    for element8 in rc_lookahead:\n",
    "                                        for element9 in ref:\n",
    "                                            _cmd = '../x264/x264 '\n",
    "                                            _cmd = _cmd + element0\n",
    "                                            _cmd = _cmd + element1\n",
    "                                            _cmd = _cmd + element2\n",
    "                                            _cmd = _cmd + element3\n",
    "                                            _cmd = _cmd + element4\n",
    "                                            _cmd = _cmd + element5\n",
    "                                            _cmd = _cmd + element6\n",
    "                                            _cmd = _cmd + element7\n",
    "                                            _cmd = _cmd + element8\n",
    "                                            _cmd = _cmd + element9\n",
    "                                            config_option.append(_cmd)\n",
    "                                            v0 = eye_2[asm.index(element0)]\n",
    "                                            v1 = eye_2[x8dct.index(element1)]\n",
    "                                            v2 = eye_2[cabac.index(element2)]\n",
    "                                            v3 = eye_2[deblock.index(element3)]\n",
    "                                            v4 = eye_2[pskip.index(element4)]\n",
    "                                            v5 = eye_2[mbtree.index(element5)]\n",
    "                                            v6 = eye_2[mixed_refs.index(element6)]\n",
    "                                            v7 = eye_2[weightb.index(element7)]\n",
    "                                            v8 = float(rc_value[rc_lookahead.index(element8)])\n",
    "                                            v9 = float(ref_value[ref.index(element9)])\n",
    "                                            all_possible_config = np.concatenate((v0, v1, v2, v3, v4, v5, v6, v7, v8, v9), axis=None)\n",
    "                                            all_possible_configs.append(all_possible_config)\n",
    "                                            # print(_cmd)\n",
    "                                            config_option.append(_cmd)\n",
    "    return config_option, all_possible_configs\n",
    "\n",
    "\n",
    "def transfer_config(all_possible_configs):\n",
    "    config_features = all_possible_configs\n",
    "    config_features = np.asarray(config_features)\n",
    "    scaler = MinMaxScaler()\n",
    "    # scaler = StandardScaler()\n",
    "    scaler.fit(config_features)\n",
    "    config_features = scaler.transform(config_features)\n",
    "    return config_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrzip_config, config_signal = generate_config()\n",
    "all_input_signal = transfer_config(config_signal)\n",
    "all_data = pd.read_csv(\"./x264.csv\", index_col=0)\n",
    "results = np.asarray(all_data[all_data['commit_num'] == 1]['time'])\n",
    "all_possible_configs_cur = np.asarray(config_signal)\n",
    "config_features = np.asarray(all_input_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoMSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T18:54:00.680448Z",
     "start_time": "2022-07-03T18:53:30.021270Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R2_list = []\n",
    "mean_re_list = []\n",
    "time_avg = 0\n",
    "for seed_num in range(1,102,5):\n",
    "    print(seed_num)\n",
    "    np.random.seed(seed_num)\n",
    "    sampled_config_ids = list(np.random.randint(len(results), size=3))\n",
    "    initial_idx = np.array_split(sampled_config_ids, 2)\n",
    "\n",
    "    learner_list = [ActiveLearner(\n",
    "                        estimator=XGBRegressor(),\n",
    "                        X_training=config_features[idx], y_training=results[idx]\n",
    "                )\n",
    "                for idx in initial_idx]\n",
    "\n",
    "    # initializing the Committee\n",
    "    committee = CommitteeRegressor(\n",
    "        learner_list=learner_list,\n",
    "        query_strategy=max_std_sampling\n",
    "    )\n",
    "\n",
    "    model=XGBRegressor()\n",
    "    n_queries = 45\n",
    "    res_al = []\n",
    "    mean_re = []\n",
    "    # median_re = []\n",
    "    start = time.time()\n",
    "    for idx in range(n_queries):\n",
    "        X_train = config_features[sampled_config_ids]\n",
    "        y_train = results[sampled_config_ids]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), sampled_config_ids)]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), sampled_config_ids)]\n",
    "        model.fit(X_train, y_train)\n",
    "        relative_error = []\n",
    "        Y_predict = model.predict(X_test)\n",
    "        relative_error = []\n",
    "        for i in range(len(X_test)):\n",
    "            RE=abs(y_test[i]-Y_predict[i])\n",
    "            relative_error.append(RE*RE)\n",
    "        res_al.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "        query_idx, query_instance = committee.query(config_features)\n",
    "        sampled_config_ids += list(query_idx)\n",
    "        committee.teach(config_features[query_idx], results[query_idx])\n",
    "    end = time.time()\n",
    "    time_avg = time_avg + end - start \n",
    "    print('time:'+ str(end - start))\n",
    "    R2_list.append(res_al)\n",
    "    # mean_re_list.append(mean_re)\n",
    "    # median_re_list.append(median_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = np.matrix(R2_list, dtype=np.float32)\n",
    "np.save('../Compare/AL-XG.npy', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossover and mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_errors(X_train, y_train, regr):\n",
    "    y_preds = regr.predict(X_train)\n",
    "    square_errors = (y_train - y_preds)**2\n",
    "    normalized_errors = (square_errors - square_errors.min()) / (square_errors.max() - square_errors.min())\n",
    "    return square_errors, normalized_errors\n",
    "\n",
    "def get_all_distances(X_train):\n",
    "    dis_metrics = euclidean_distances(X_train, X_train)\n",
    "    dis_metrics_sum = np.sum(dis_metrics, axis=1)\n",
    "    normalized_dis = (dis_metrics_sum - dis_metrics_sum.min()) / (dis_metrics_sum.max() - dis_metrics_sum.min())\n",
    "    return dis_metrics, normalized_dis\n",
    "\n",
    "def get_ids_by_score(normalized_errors, normalized_dis, dis_metrics, sampled_config_ids, already_crossovered_config_id_list, ratio=0.5):\n",
    "    # print(ratio)\n",
    "    all_possible_configs_pairs = []\n",
    "    all_scores = ratio*normalized_errors + (1-ratio)*normalized_dis\n",
    "    sorted_idx_desc = all_scores.argsort()[:][::-1]\n",
    "    # config_id_1 = sorted_idx_desc[0]\n",
    "    dis_median = np.median(dis_metrics)\n",
    "    # dis_median = 0\n",
    "    for config_id_1 in sorted_idx_desc:\n",
    "        # second_idx_desc = get_second_point_list_by_distance(dis_metrics, config_id_1)\n",
    "        for config_id in sorted_idx_desc:\n",
    "            if dis_metrics[config_id_1][config_id] >= dis_median:\n",
    "                config_id_1_ori, config_id_2_ori = sampled_config_ids[config_id_1], sampled_config_ids[config_id]\n",
    "                if config_id_1_ori not in already_crossovered_config_id_list and config_id_2_ori not in already_crossovered_config_id_list:\n",
    "                # if {config_id_1_ori, config_id_2_ori} not in already_crossovered_config_id_list:\n",
    "                    all_possible_configs_pairs.append([config_id_1_ori, config_id_2_ori])\n",
    "                    return config_id_1_ori, config_id_2_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosssover(config_id_1, config_id_2,  weights, sampled_config_ids, already_crossovered_config_id_list):\n",
    "    global count_failed\n",
    "    # dis_metrics, normalized_dis = get_all_weighted_distance(X_train, feature_weights)\n",
    "    # while True:\n",
    "    # TODO: need to be improved\n",
    "\n",
    "    # config_id_1, config_id_2 = get_ids_by_score_new(normalized_errors, normalized_dis, dis_metrics, sampled_config_ids, already_crossovered_config_id_list, ratio)\n",
    "        # config_id_1, config_id_2 = sampled_config_ids[config_id_1], sampled_config_ids[config_id_2]\n",
    "        # if config_id_1 < len(config_features) and config_id_2 < len(config_features):\n",
    "            # break\n",
    "    count_loop = 0\n",
    "    new_configs = []\n",
    "    # refine the weight based on the intuitives\n",
    "    # weights = feature_weights\n",
    "    algo_count = 18\n",
    "    # algo_weight = np.sum(np.absolute(weights)[:algo_count])\n",
    "    algo_weight = np.max(np.absolute(weights)[:algo_count])\n",
    "    # cut_index_prob_raw = np.insert(np.absolute(weights)[algo_count:], 0, algo_weight)\n",
    "    # re_fined_weights = np.concatenate([np.repeat(algo_weight, np.absolute(weights)[algo_count:]])\n",
    "    cut_index_prob_raw = np.insert(np.absolute(weights)[algo_count:], 0, algo_weight)\n",
    "    cut_index_prob = cut_index_prob_raw/cut_index_prob_raw.sum()\n",
    "    already_cut_ids = []\n",
    "\n",
    "    while True:\n",
    "        count_loop += 1\n",
    "        cut_index = np.random.randint(0, 18)\n",
    "        # cut_index = np.random.choice(5, 1, p=cut_index_prob)[0]\n",
    "        if cut_index == 17:\n",
    "            cut_index -= 1\n",
    "        new_config_1 = np.concatenate([all_possible_configs_cur[config_id_1][:cut_index+1], all_possible_configs_cur[config_id_2][cut_index+1:]])\n",
    "        new_config_1_ids = np.where((all_possible_configs_cur==new_config_1).all(axis=1))[0]\n",
    "        if new_config_1_ids.size > 0 and new_config_1_ids[0] not in sampled_config_ids:\n",
    "            # new_config_1_id = np.where((all_possible_configs_cur==new_config_1).all(axis=1))[0][0]\n",
    "            # if new_config_1_id not in sampled_config_ids:\n",
    "            # new_configs.append(new_config_1)\n",
    "            new_config_2 = np.concatenate([all_possible_configs_cur[config_id_2][:cut_index+1], all_possible_configs_cur[config_id_1][cut_index+1:]])\n",
    "            new_config_2_ids = np.where((all_possible_configs_cur==new_config_2).all(axis=1))[0]\n",
    "            if new_config_2_ids.size > 0 and new_config_2_ids[0] not in sampled_config_ids:\n",
    "                new_configs = [new_config_1, new_config_2]\n",
    "                break\n",
    "        if count_loop == 100:\n",
    "            count_failed +=1\n",
    "            new_config_1, new_config_2 = np.random.randint(len(config_features), size=2)\n",
    "            new_configs = [all_possible_configs_cur[config_id_1], all_possible_configs_cur[config_id_2]]\n",
    "            # already_crossovered_config_id_list.append({config_id_1, config_id_2}) \n",
    "            break\n",
    "    # already_crossovered_config_id_list.append({config_id_1, config_id_2})\n",
    "    already_crossovered_config_id_list += [config_id_1, config_id_2]\n",
    "    return new_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(pre_configs, weights):\n",
    "    # weights = regr.coef_\n",
    "    algo_count = 18\n",
    "    algo_weight = np.max(np.absolute(weights)[:algo_count])\n",
    "    # algo_weight = np.sum(np.absolute(weights)[:algo_count])\n",
    "    # algo_weight = np.mean(np.absolute(weights)[:algo_count])\n",
    "    # np.sum(np.absolute(weights)[:algo_count])\n",
    "    # re_fined_weights = np.concatenate([np.repeat(algo_weight, np.absolute(weights)[algo_count:]])\n",
    "    cut_index_prob_raw = np.insert(np.absolute(weights)[algo_count:], 0, algo_weight)\n",
    "    cut_index_prob = cut_index_prob_raw/cut_index_prob_raw.sum()\n",
    "    new_configs = []\n",
    "    config_len = len(pre_configs[0])\n",
    "    for pre_config in pre_configs:\n",
    "        # mut_index = np.random.randint(0, config_len)\n",
    "        i = 0\n",
    "        mut_index = np.random.choice(len(cut_index_prob), 1, p=cut_index_prob)[0]\n",
    "        while i<100:\n",
    "            i += 1\n",
    "            possible_val = np.random.choice(np.unique(all_possible_configs_cur[:, mut_index]))\n",
    "            new_config = pre_config.copy()\n",
    "            if new_config[mut_index] != possible_val:\n",
    "                new_config[mut_index] = possible_val\n",
    "                new_config_ids = np.where((all_possible_configs_cur[:]==new_config).all(axis=1))[0]\n",
    "                if new_config_ids.size > 0:\n",
    "                    break\n",
    "        new_configs.append(new_config)\n",
    "    return new_configs + pre_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r2_mutate=[]\n",
    "mre_mutate = []\n",
    "time_avg_mutate = 0\n",
    "for rand_num in range(0,101,5):\n",
    "    r_square_list = []\n",
    "    mre = []\n",
    "    mean_squared_all_list = []\n",
    "    already_crossovered_config_id_list = []\n",
    "    coefs_list = []\n",
    "    count_failed = 0\n",
    "    \n",
    "    print(rand_num)\n",
    "    start = time.time()\n",
    "    np.random.seed(rand_num)\n",
    "    sampled_config_ids = np.random.randint(len(results), size=6)\n",
    "    X_train, X_test, y_train, y_test=train_test_split(config_features,results, test_size=0.8, random_state=rand_num)\n",
    "    # try:\n",
    "    for i in range(27):\n",
    "    \n",
    "            X_train = config_features[sampled_config_ids]\n",
    "            y_train= results[sampled_config_ids]\n",
    "    \n",
    "            X_test = config_features[~np.isin(np.arange(len(config_features)), sampled_config_ids)]\n",
    "            y_test = results[~np.isin(np.arange(len(config_features)), sampled_config_ids)]\n",
    "    \n",
    "            regr = XGBRegressor(learning_rate=0.1)\n",
    "            regr.fit(X_train, y_train)\n",
    "            y_pred = regr.predict(X_test)\n",
    "            # coefs_lst.append(regr.coef_)\n",
    "            y_pred_all = regr.predict(X_test)\n",
    "        \n",
    "            # r_square_list.append(r2_score(y_test, y_pred))\n",
    "            # mean_squared_list.append(mean_squared_error(y_test, y_pred))\n",
    "            relative_error = []\n",
    "            for i in range(len(X_test)):\n",
    "                RE=abs(y_test[i]-y_pred[i])\n",
    "                relative_error.append(RE*RE)\n",
    "            mre.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "        \n",
    "            # mean_squared_all_list.append(mean_squared_error(y_test, y_pred_all))\n",
    "            feature_weights = regr.feature_importances_\n",
    "            square_errors, normalized_errors = get_all_errors(X_train, y_train, regr)\n",
    "            dis_metrics, normalized_dis = get_all_distances(X_train)\n",
    "            ratio = 0.9\n",
    "            if np.sum(square_errors) < 0.1:\n",
    "                ratio = 0\n",
    "            config_id_1, config_id_2 = get_ids_by_score(normalized_errors, normalized_dis, dis_metrics, sampled_config_ids, already_crossovered_config_id_list, ratio)\n",
    "    \n",
    "            new_configs = crosssover(config_id_1, config_id_2, feature_weights, sampled_config_ids, already_crossovered_config_id_list)\n",
    "            new_configs = mutation(new_configs, feature_weights)\n",
    "    \n",
    "            for new_config in new_configs:\n",
    "                new_config_ids = np.where((all_possible_configs_cur==new_config).all(axis=1))[0]\n",
    "                if new_config_ids.size > 0:\n",
    "                    new_config_id = new_config_ids[0]\n",
    "                    sampled_config_ids = np.append(sampled_config_ids, new_config_id)\n",
    "    # r2_mutate.append(r_square_list)\n",
    "    mre_mutate.append(mre)\n",
    "    end = time.time()\n",
    "    time_avg_mutate = time_avg_mutate + end - start \n",
    "    print(end - start)\n",
    "    # except:\n",
    "    #    print(\"An exception occurred\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(0, len(mre_mutate)):\n",
    "    subset = [mre_mutate[i][idx] for idx in [0, 2, 4, 7, 9, 11, 13, 16]]\n",
    "    data.append(subset)\n",
    "\n",
    "data_t = np.transpose(data)\n",
    "for element in data_t:\n",
    "    print(mean(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "R2 = np.matrix(mre_mutate, dtype=np.float32)\n",
    "print(R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../Compare/Mutate_mre.npy', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T05:51:26.734865Z",
     "start_time": "2021-12-28T05:51:17.999453Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_random = []\n",
    "time_random = 0\n",
    "for rand_num in range(1,102,5): \n",
    "    print(rand_num)\n",
    "    start = time.time()\n",
    "    np.random.seed(rand_num)\n",
    "    sampled_config_ids_rand = list(np.random.randint(len(X_train), size=4))\n",
    "    n_queries = 41\n",
    "    res_al_rand = []\n",
    "    for idx in range(n_queries):\n",
    "        X_train = config_features[sampled_config_ids_rand]\n",
    "        y_train = results[sampled_config_ids_rand]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), sampled_config_ids_rand)]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), sampled_config_ids_rand)]\n",
    "        model=RandomForestRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        relative_error = []\n",
    "        Y_predict = model.predict(X_test)\n",
    "        for i in range(len(X_test)):\n",
    "            RE = abs(y_test[i]-Y_predict[i])\n",
    "            relative_error.append(RE*RE)\n",
    "        mean_re.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "        # res_al_rand.append(model.score(X_test,y_test))\n",
    "        query_idx = np.random.randint(len(config_features), size=1)\n",
    "        sampled_config_ids_rand += list(query_idx)\n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "    time_random += end-start\n",
    "    r2_random.append(mean_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(0, len(r2_random)):\n",
    "    subset = [r2_random[i][idx] for idx in range(0, 41, 5)]\n",
    "    data.append(subset)\n",
    "data_t = np.transpose(data)\n",
    "for element in data_t:\n",
    "    print(mean(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = np.matrix(r2_random, dtype=np.float32)\n",
    "np.save('../Compare/Random_mre.npy', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.load('../Compare/FLASH/x264_AllNumeric.npy')\n",
    "r2_list=[]\n",
    "for l in [5,10,15,20,25,30,35,40]:\n",
    "    r2 = []   \n",
    "    for i in range(0, len(index)):\n",
    "        print(index[i,:l])\n",
    "        X_train = config_features[index[i,:l]]\n",
    "        y_train = results[index[i,:l]]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), index[i,:l])]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), index[i,:l])]\n",
    "        model=XGBRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        r2.append(model.score(X_test,y_test))\n",
    "    r2_list.append(r2)\n",
    "\n",
    "R2 = np.matrix(r2_list, dtype=np.float32)\n",
    "# np.save('../Compare/FLASH_x264.npy', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.load('../Compare/SPL_Conqueror/x264/divDistBased.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_list=[]\n",
    "for l in [5,10,15,20,25,30,35,40]:\n",
    "    r2 = []\n",
    "    mean_re = []\n",
    "    for i in range(0, len(index)):\n",
    "        X_train = config_features[index[i,:l]]\n",
    "        y_train = results[index[i,:l]]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), index[i,:l])]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), index[i,:l])]\n",
    "        model=XGBRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        relative_error = []\n",
    "        Y_predict = model.predict(X_test)\n",
    "        for i in range(len(X_test)):\n",
    "            RE = abs(y_test[i]-Y_predict[i])\n",
    "            relative_error.append(RE*RE)\n",
    "        mean_re.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "        # r2.append(model.score(X_test,y_test))\n",
    "    r2_list.append(mean_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in r2_list:\n",
    "    print(mean(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = np.matrix(r2_list, dtype=np.float32)\n",
    "np.save('../Compare/SPL_Conqueror/SPL_solverBased_x264_mre.npy', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NsbS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.load('../Compare/NsbS/x264/NsbS.npy')\n",
    "r2_list=[]\n",
    "for l in [5,10,15,20,25,30,35,40]:\n",
    "    r2 = []\n",
    "    for i in range(0, len(index)):\n",
    "        X_train = config_features[index[i,:l]]\n",
    "        y_train = results[index[i,:l]]\n",
    "        X_test = config_features[~np.isin(np.arange(len(config_features)), index[i,:l])]\n",
    "        y_test = results[~np.isin(np.arange(len(config_features)), index[i,:l])]\n",
    "        model=XGBRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        relative_error = []\n",
    "        Y_predict = model.predict(X_test)\n",
    "        for i in range(len(X_test)):\n",
    "            RE = abs(y_test[i]-Y_predict[i])\n",
    "            relative_error.append(RE*RE)\n",
    "        r2.append(sqrt(sum(relative_error)/len(relative_error)))\n",
    "        # r2.append(model.score(X_test,y_test))\n",
    "    r2_list.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in r2_list:\n",
    "    print(mean(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = np.matrix(r2_list, dtype=np.float32)\n",
    "#np.save('../Compare/NsbS/x264/result_mre.npy', R2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
